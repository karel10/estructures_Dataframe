{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f8bd3a-8e14-4698-b69b-78ae60d97564",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Realizar web scraping de dos de estas tres posibles páginas web:\n",
    "a) http://quotes.toscrape.com ; b) https://www.bolsamadrid.es ; c) www.wikipedia.es (buscar algún contenido primero)\n",
    "\n",
    "Hacer scraping primero con BeautifulSoup, y luego otro con Selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc2a74-908c-4054-a64c-7ac6714c584d",
   "metadata": {},
   "source": [
    "Webs seleccionadas:\n",
    "\n",
    "http://quotes.toscrape.com/  (por su sencillez, de hecho está dedicada a la práctica del \"scraping\")\n",
    "\n",
    "https://es.wikipedia.org/wiki/Carl_Weathers  (por su actualidad reciente, dado el reciente fallecimiento del famoso actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc687953-7732-4621-957e-857aae1e33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "# import sys\n",
    "\n",
    "# Para \"http://quotes.toscrape.com/\" mediante BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Para \"https://es.wikipedia.org/wiki/Carl_Weathers\" y para \"https://ground.news\" mediante Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "# Automatiza la búsqueda e instalación de la versión de driver correcta para el navegador disponible en el OS:\n",
    "from webdriver_manager.firefox import GeckoDriverManager  # https://pypi.org/project/webdriver-manager/\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Para https://ground.news usando Scrapy (hecho fuera del notebook)\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ed77c-dbd1-416f-ae72-70e9a1db7b63",
   "metadata": {},
   "source": [
    "### Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b2f5a-52bd-43f5-9bd3-61953aa24e61",
   "metadata": {},
   "source": [
    "Empezamos aplicando BeautifulSoup a la web \"Quotes to Scrape\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270421f-8909-4402-bf4b-fb2056f32c1c",
   "metadata": {},
   "source": [
    "URL con la que trabajaremos primero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e4414c-325b-434c-b328-c6d925eade8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://quotes.toscrape.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c178e-8dc6-4eb3-8291-ae3b5e566046",
   "metadata": {},
   "source": [
    "Acceso al contenido HTML de la URL mediante requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fa36d5-25f6-44b7-a421-82bba65a00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)   # Mediante requests obtenemos el contenido de la URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e2d2d2-a743-4263-a221-dc6cacb243a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Quotes to Scrape\n",
      "  </title>\n",
      "  <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/static/main.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"container\">\n",
      "   <div class=\"row header-box\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <h1>\n",
      "      <a href=\"/\" style=\"text-decoration: none\">\n",
      "       Quotes to Scrape\n",
      "      </a>\n",
      "     </h1>\n",
      "    </div>\n",
      "    <div class=\"col-md-4\">\n",
      "     <p>\n",
      "      <a href=\"/login\">\n",
      "       Login\n",
      "      </a>\n",
      "     </p>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"row\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Albert Einstein\n",
      "       </small>\n",
      "       <a href=\"/author/Albert-Einstein\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/change/page/1/\">\n",
      "        change\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">\n",
      "        deep-thoughts\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/thinking/page/1/\">\n",
      "        thinking\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/world/page/1/\">\n",
      "        world\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        J.K. Rowling\n",
      "       </small>\n",
      "       <a href=\"/author/J-K-Rowling\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"abilities,choices\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/abilities/page/1/\">\n",
      "        abilities\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/choices/page/1/\">\n",
      "        choices\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Albert Einstein\n",
      "       </small>\n",
      "       <a href=\"/author/Albert-Einstein\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/inspirational/page/1/\">\n",
      "        inspirational\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/life/page/1/\">\n",
      "        life\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/live/page/1/\">\n",
      "        live\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/miracle/page/1/\">\n",
      "        miracle\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/miracles/page/1/\">\n",
      "        miracles\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Jane Austen\n",
      "       </small>\n",
      "       <a href=\"/author/Jane-Austen\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"aliteracy,books,classic,humor\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/aliteracy/page/1/\">\n",
      "        aliteracy\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/books/page/1/\">\n",
      "        books\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/classic/page/1/\">\n",
      "        classic\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/humor/page/1/\">\n",
      "        humor\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Marilyn Monroe\n",
      "       </small>\n",
      "       <a href=\"/author/Marilyn-Monroe\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"be-yourself,inspirational\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/be-yourself/page/1/\">\n",
      "        be-yourself\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/inspirational/page/1/\">\n",
      "        inspirational\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “Try not to become a man of success. Rather become a man of value.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Albert Einstein\n",
      "       </small>\n",
      "       <a href=\"/author/Albert-Einstein\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"adulthood,success,value\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/adulthood/page/1/\">\n",
      "        adulthood\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/success/page/1/\">\n",
      "        success\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/value/page/1/\">\n",
      "        value\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “It is better to be hated for what you are than to be loved for what you are not.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        André Gide\n",
      "       </small>\n",
      "       <a href=\"/author/Andre-Gide\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"life,love\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/life/page/1/\">\n",
      "        life\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/love/page/1/\">\n",
      "        love\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “I have not failed. I've just found 10,000 ways that won't work.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Thomas A. Edison\n",
      "       </small>\n",
      "       <a href=\"/author/Thomas-A-Edison\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/edison/page/1/\">\n",
      "        edison\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/failure/page/1/\">\n",
      "        failure\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/inspirational/page/1/\">\n",
      "        inspirational\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/paraphrased/page/1/\">\n",
      "        paraphrased\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Eleanor Roosevelt\n",
      "       </small>\n",
      "       <a href=\"/author/Eleanor-Roosevelt\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"misattributed-eleanor-roosevelt\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">\n",
      "        misattributed-eleanor-roosevelt\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “A day without sunshine is like, you know, night.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Steve Martin\n",
      "       </small>\n",
      "       <a href=\"/author/Steve-Martin\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"humor,obvious,simile\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/humor/page/1/\">\n",
      "        humor\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/obvious/page/1/\">\n",
      "        obvious\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/simile/page/1/\">\n",
      "        simile\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <nav>\n",
      "      <ul class=\"pager\">\n",
      "       <li class=\"next\">\n",
      "        <a href=\"/page/2/\">\n",
      "         Next\n",
      "         <span aria-hidden=\"true\">\n",
      "          →\n",
      "         </span>\n",
      "        </a>\n",
      "       </li>\n",
      "      </ul>\n",
      "     </nav>\n",
      "    </div>\n",
      "    <div class=\"col-md-4 tags-box\">\n",
      "     <h2>\n",
      "      Top Ten tags\n",
      "     </h2>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/love/\" style=\"font-size: 28px\">\n",
      "       love\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/inspirational/\" style=\"font-size: 26px\">\n",
      "       inspirational\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/life/\" style=\"font-size: 26px\">\n",
      "       life\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/humor/\" style=\"font-size: 24px\">\n",
      "       humor\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/books/\" style=\"font-size: 22px\">\n",
      "       books\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/reading/\" style=\"font-size: 14px\">\n",
      "       reading\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/friendship/\" style=\"font-size: 10px\">\n",
      "       friendship\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/friends/\" style=\"font-size: 8px\">\n",
      "       friends\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/truth/\" style=\"font-size: 8px\">\n",
      "       truth\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/simile/\" style=\"font-size: 6px\">\n",
      "       simile\n",
      "      </a>\n",
      "     </span>\n",
      "    </div>\n",
      "   </div>\n",
      "  </div>\n",
      "  <footer class=\"footer\">\n",
      "   <div class=\"container\">\n",
      "    <p class=\"text-muted\">\n",
      "     Quotes by:\n",
      "     <a href=\"https://www.goodreads.com/quotes\">\n",
      "      GoodReads.com\n",
      "     </a>\n",
      "    </p>\n",
      "    <p class=\"copyright\">\n",
      "     Made with\n",
      "     <span class=\"zyte\">\n",
      "      ❤\n",
      "     </span>\n",
      "     by\n",
      "     <a class=\"zyte\" href=\"https://www.zyte.com\">\n",
      "      Zyte\n",
      "     </a>\n",
      "    </p>\n",
      "   </div>\n",
      "  </footer>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.text, 'html')   # Se genera un objeto BeautifulSoup que incorpora el texto de la página cargada en \"page\", parseando como html.\n",
    "print(soup.prettify()) # prettify() genera indentación para hacerlo más legible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b676a-3175-4509-ad6a-eabf3f120f88",
   "metadata": {},
   "source": [
    "Podemos buscar etiquetas HTML y sus atributos (como \"class\", \"href\", etc). En esta web concreta, para buscar un \"div\" referido a una cita, después de mirar el código deducimos que nos conviene uno que tenga como clase el término \"quote\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c8b27-fc85-493c-86c3-f4ac611298ca",
   "metadata": {},
   "source": [
    "En base a eso, podemos extraer el texto correspondiente de cada cita de la página, así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fe67101-de9c-43fb-8012-be043b658b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 citas en el objeto 'soup'.\n",
      "\n",
      "Esto es lo que continene el primer objeto tipo \"quote\" de la lista extraída:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       "<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
       "<span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       "<a href=\"/author/Albert-Einstein\">(about)</a>\n",
       "</span>\n",
       "<div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
       "<a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
       "<a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
       "<a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
       "<a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usamos el método find_all() de los objetos BeautifulSoup:\n",
    "citas = soup.find_all('div', class_ = \"quote\")  # Esto nos da una lista de resultados. Con find() en lugar de find_all() obtendríamos uno solo.\n",
    "\n",
    "print(len(citas),\"citas en el objeto 'soup'.\\n\")  # Hay diez resultados en la lista\n",
    "\n",
    "print(\"Esto es lo que continene el primer objeto tipo \\\"quote\\\" de la lista extraída:\")\n",
    "citas[0]   # Como con find_all() obtenemos una lista, accedemos a uno de sus elementos para mostrar su estructura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb629c-ec26-4921-a75e-da6b6d18a028",
   "metadata": {},
   "source": [
    "Según el uso que se vaya a hacer, es conveniente tener en cuenta que hay once páginas que escrapear, por lo tanto en este caso repetimos el proceso mediante un loop para recoger todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2a546c2-2320-46fc-831a-18af61b1b13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Albert Einstein',\n",
       "  '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
       "  ['change', 'deep-thoughts', 'thinking', 'world']],\n",
       " ['J.K. Rowling',\n",
       "  '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
       "  ['abilities', 'choices']],\n",
       " ['Albert Einstein',\n",
       "  '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
       "  ['inspirational', 'life', 'live', 'miracle', 'miracles']],\n",
       " ['Jane Austen',\n",
       "  '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
       "  ['aliteracy', 'books', 'classic', 'humor']],\n",
       " ['Marilyn Monroe',\n",
       "  \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
       "  ['be-yourself', 'inspirational']],\n",
       " ['Albert Einstein',\n",
       "  '“Try not to become a man of success. Rather become a man of value.”',\n",
       "  ['adulthood', 'success', 'value']],\n",
       " ['André Gide',\n",
       "  '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
       "  ['life', 'love']],\n",
       " ['Thomas A. Edison',\n",
       "  \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
       "  ['edison', 'failure', 'inspirational', 'paraphrased']],\n",
       " ['Eleanor Roosevelt',\n",
       "  \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
       "  ['misattributed-eleanor-roosevelt']],\n",
       " ['Steve Martin',\n",
       "  '“A day without sunshine is like, you know, night.”',\n",
       "  ['humor', 'obvious', 'simile']],\n",
       " ['Marilyn Monroe',\n",
       "  \"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\",\n",
       "  ['friends', 'heartbreak', 'inspirational', 'life', 'love', 'sisters']],\n",
       " ['J.K. Rowling',\n",
       "  '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”',\n",
       "  ['courage', 'friends']],\n",
       " ['Albert Einstein',\n",
       "  \"“If you can't explain it to a six year old, you don't understand it yourself.”\",\n",
       "  ['simplicity', 'understand']],\n",
       " ['Bob Marley',\n",
       "  \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\",\n",
       "  ['love']],\n",
       " ['Dr. Seuss',\n",
       "  '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”',\n",
       "  ['fantasy']],\n",
       " ['Douglas Adams',\n",
       "  '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”',\n",
       "  ['life', 'navigation']],\n",
       " ['Elie Wiesel',\n",
       "  \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\",\n",
       "  ['activism',\n",
       "   'apathy',\n",
       "   'hate',\n",
       "   'indifference',\n",
       "   'inspirational',\n",
       "   'love',\n",
       "   'opposite',\n",
       "   'philosophy']],\n",
       " ['Friedrich Nietzsche',\n",
       "  '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”',\n",
       "  ['friendship',\n",
       "   'lack-of-friendship',\n",
       "   'lack-of-love',\n",
       "   'love',\n",
       "   'marriage',\n",
       "   'unhappy-marriage']],\n",
       " ['Mark Twain',\n",
       "  '“Good friends, good books, and a sleepy conscience: this is the ideal life.”',\n",
       "  ['books', 'contentment', 'friends', 'friendship', 'life']],\n",
       " ['Allen Saunders',\n",
       "  '“Life is what happens to us while we are making other plans.”',\n",
       "  ['fate', 'life', 'misattributed-john-lennon', 'planning', 'plans']],\n",
       " ['Pablo Neruda',\n",
       "  '“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”',\n",
       "  ['love', 'poetry']],\n",
       " ['Ralph Waldo Emerson',\n",
       "  '“For every minute you are angry you lose sixty seconds of happiness.”',\n",
       "  ['happiness']],\n",
       " ['Mother Teresa',\n",
       "  '“If you judge people, you have no time to love them.”',\n",
       "  ['attributed-no-source']],\n",
       " ['Garrison Keillor',\n",
       "  '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”',\n",
       "  ['humor', 'religion']],\n",
       " ['Jim Henson',\n",
       "  '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”',\n",
       "  ['humor']],\n",
       " ['Dr. Seuss',\n",
       "  '“Today you are You, that is truer than true. There is no one alive who is Youer than You.”',\n",
       "  ['comedy', 'life', 'yourself']],\n",
       " ['Albert Einstein',\n",
       "  '“If you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales.”',\n",
       "  ['children', 'fairy-tales']],\n",
       " ['J.K. Rowling',\n",
       "  '“It is impossible to live without failing at something, unless you live so cautiously that you might as well not have lived at all - in which case, you fail by default.”',\n",
       "  []],\n",
       " ['Albert Einstein',\n",
       "  '“Logic will get you from A to Z; imagination will get you everywhere.”',\n",
       "  ['imagination']],\n",
       " ['Bob Marley',\n",
       "  '“One good thing about music, when it hits you, you feel no pain.”',\n",
       "  ['music']],\n",
       " ['Dr. Seuss',\n",
       "  \"“The more that you read, the more things you will know. The more that you learn, the more places you'll go.”\",\n",
       "  ['learning', 'reading', 'seuss']],\n",
       " ['J.K. Rowling',\n",
       "  '“Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real?”',\n",
       "  ['dumbledore']],\n",
       " ['Bob Marley',\n",
       "  '“The truth is, everyone is going to hurt you. You just got to find the ones worth suffering for.”',\n",
       "  ['friendship']],\n",
       " ['Mother Teresa',\n",
       "  '“Not all of us can do great things. But we can do small things with great love.”',\n",
       "  ['misattributed-to-mother-teresa', 'paraphrased']],\n",
       " ['J.K. Rowling',\n",
       "  '“To the well-organized mind, death is but the next great adventure.”',\n",
       "  ['death', 'inspirational']],\n",
       " ['Charles M. Schulz',\n",
       "  \"“All you need is love. But a little chocolate now and then doesn't hurt.”\",\n",
       "  ['chocolate', 'food', 'humor']],\n",
       " ['William Nicholson',\n",
       "  \"“We read to know we're not alone.”\",\n",
       "  ['misattributed-to-c-s-lewis', 'reading']],\n",
       " ['Albert Einstein',\n",
       "  '“Any fool can know. The point is to understand.”',\n",
       "  ['knowledge', 'learning', 'understanding', 'wisdom']],\n",
       " ['Jorge Luis Borges',\n",
       "  '“I have always imagined that Paradise will be a kind of library.”',\n",
       "  ['books', 'library']],\n",
       " ['George Eliot',\n",
       "  '“It is never too late to be what you might have been.”',\n",
       "  ['inspirational']],\n",
       " ['George R.R. Martin',\n",
       "  '“A reader lives a thousand lives before he dies, said Jojen. The man who never reads lives only one.”',\n",
       "  ['read', 'readers', 'reading', 'reading-books']],\n",
       " ['C.S. Lewis',\n",
       "  '“You can never get a cup of tea large enough or a book long enough to suit me.”',\n",
       "  ['books', 'inspirational', 'reading', 'tea']],\n",
       " ['Marilyn Monroe',\n",
       "  '“You believe lies so you eventually learn to trust no one but yourself.”',\n",
       "  []],\n",
       " ['Marilyn Monroe',\n",
       "  '“If you can make a woman laugh, you can make her do anything.”',\n",
       "  ['girls', 'love']],\n",
       " ['Albert Einstein',\n",
       "  '“Life is like riding a bicycle. To keep your balance, you must keep moving.”',\n",
       "  ['life', 'simile']],\n",
       " ['Marilyn Monroe',\n",
       "  '“The real lover is the man who can thrill you by kissing your forehead or smiling into your eyes or just staring into space.”',\n",
       "  ['love']],\n",
       " ['Marilyn Monroe',\n",
       "  \"“A wise girl kisses but doesn't love, listens but doesn't believe, and leaves before she is left.”\",\n",
       "  ['attributed-no-source']],\n",
       " ['Martin Luther King Jr.',\n",
       "  '“Only in the darkness can you see the stars.”',\n",
       "  ['hope', 'inspirational']],\n",
       " ['J.K. Rowling',\n",
       "  '“It matters not what someone is born, but what they grow to be.”',\n",
       "  ['dumbledore']],\n",
       " ['James Baldwin',\n",
       "  '“Love does not begin and end the way we seem to think it does. Love is a battle, love is a war; love is a growing up.”',\n",
       "  ['love']],\n",
       " ['Jane Austen',\n",
       "  '“There is nothing I would not do for those who are really my friends. I have no notion of loving people by halves, it is not my nature.”',\n",
       "  ['friendship', 'love']],\n",
       " ['Eleanor Roosevelt',\n",
       "  '“Do one thing every day that scares you.”',\n",
       "  ['attributed', 'fear', 'inspiration']],\n",
       " ['Marilyn Monroe',\n",
       "  '“I am good, but not an angel. I do sin, but I am not the devil. I am just a small girl in a big world trying to find someone to love.”',\n",
       "  ['attributed-no-source']],\n",
       " ['Albert Einstein',\n",
       "  '“If I were not a physicist, I would probably be a musician. I often think in music. I live my daydreams in music. I see my life in terms of music.”',\n",
       "  ['music']],\n",
       " ['Haruki Murakami',\n",
       "  '“If you only read the books that everyone else is reading, you can only think what everyone else is thinking.”',\n",
       "  ['books', 'thought']],\n",
       " ['Alexandre Dumas fils',\n",
       "  '“The difference between genius and stupidity is: genius has its limits.”',\n",
       "  ['misattributed-to-einstein']],\n",
       " ['Stephenie Meyer',\n",
       "  \"“He's like a drug for you, Bella.”\",\n",
       "  ['drug', 'romance', 'simile']],\n",
       " ['Ernest Hemingway',\n",
       "  '“There is no friend as loyal as a book.”',\n",
       "  ['books', 'friends', 'novelist-quotes']],\n",
       " ['Helen Keller',\n",
       "  '“When one door of happiness closes, another opens; but often we look so long at the closed door that we do not see the one which has been opened for us.”',\n",
       "  ['inspirational']],\n",
       " ['George Bernard Shaw',\n",
       "  \"“Life isn't about finding yourself. Life is about creating yourself.”\",\n",
       "  ['inspirational', 'life', 'yourself']],\n",
       " ['Charles Bukowski',\n",
       "  \"“That's the problem with drinking, I thought, as I poured myself a drink. If something bad happens you drink in an attempt to forget; if something good happens you drink in order to celebrate; and if nothing happens you drink to make something happen.”\",\n",
       "  ['alcohol']],\n",
       " ['Suzanne Collins',\n",
       "  '“You don’t forget the face of the person who was your last hope.”',\n",
       "  ['the-hunger-games']],\n",
       " ['Suzanne Collins',\n",
       "  \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\",\n",
       "  ['humor']],\n",
       " ['C.S. Lewis',\n",
       "  '“To love at all is to be vulnerable. Love anything and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable.”',\n",
       "  ['love']],\n",
       " ['J.R.R. Tolkien',\n",
       "  '“Not all those who wander are lost.”',\n",
       "  ['bilbo', 'journey', 'lost', 'quest', 'travel', 'wander']],\n",
       " ['J.K. Rowling',\n",
       "  '“Do not pity the dead, Harry. Pity the living, and, above all those who live without love.”',\n",
       "  ['live-death-love']],\n",
       " ['Ernest Hemingway',\n",
       "  '“There is nothing to writing. All you do is sit down at a typewriter and bleed.”',\n",
       "  ['good', 'writing']],\n",
       " ['Ralph Waldo Emerson',\n",
       "  '“Finish each day and be done with it. You have done what you could. Some blunders and absurdities no doubt crept in; forget them as soon as you can. Tomorrow is a new day. You shall begin it serenely and with too high a spirit to be encumbered with your old nonsense.”',\n",
       "  ['life', 'regrets']],\n",
       " ['Mark Twain',\n",
       "  '“I have never let my schooling interfere with my education.”',\n",
       "  ['education']],\n",
       " ['Dr. Seuss',\n",
       "  \"“I have heard there are troubles of more than one kind. Some come from ahead and some come from behind. But I've bought a big bat. I'm all ready you see. Now my troubles are going to have troubles with me!”\",\n",
       "  ['troubles']],\n",
       " ['Alfred Tennyson',\n",
       "  '“If I had a flower for every time I thought of you...I could walk through my garden forever.”',\n",
       "  ['friendship', 'love']],\n",
       " ['Charles Bukowski',\n",
       "  '“Some people never go crazy. What truly horrible lives they must lead.”',\n",
       "  ['humor']],\n",
       " ['Terry Pratchett',\n",
       "  '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”',\n",
       "  ['humor', 'open-mind', 'thinking']],\n",
       " ['Dr. Seuss',\n",
       "  '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”',\n",
       "  ['humor', 'philosophy']],\n",
       " ['J.D. Salinger',\n",
       "  \"“What really knocks me out is a book that, when you're all done reading it, you wish the author that wrote it was a terrific friend of yours and you could call him up on the phone whenever you felt like it. That doesn't happen much, though.”\",\n",
       "  ['authors', 'books', 'literature', 'reading', 'writing']],\n",
       " ['George Carlin',\n",
       "  '“The reason I talk to myself is because I’m the only one whose answers I accept.”',\n",
       "  ['humor', 'insanity', 'lies', 'lying', 'self-indulgence', 'truth']],\n",
       " ['John Lennon',\n",
       "  \"“You may say I'm a dreamer, but I'm not the only one. I hope someday you'll join us. And the world will live as one.”\",\n",
       "  ['beatles',\n",
       "   'connection',\n",
       "   'dreamers',\n",
       "   'dreaming',\n",
       "   'dreams',\n",
       "   'hope',\n",
       "   'inspirational',\n",
       "   'peace']],\n",
       " ['W.C. Fields',\n",
       "  '“I am free of all prejudice. I hate everyone equally. ”',\n",
       "  ['humor', 'sinister']],\n",
       " ['Ayn Rand',\n",
       "  \"“The question isn't who is going to let me; it's who is going to stop me.”\",\n",
       "  []],\n",
       " ['Mark Twain',\n",
       "  \"“′Classic′ - a book which people praise and don't read.”\",\n",
       "  ['books', 'classic', 'reading']],\n",
       " ['Albert Einstein',\n",
       "  '“Anyone who has never made a mistake has never tried anything new.”',\n",
       "  ['mistakes']],\n",
       " ['Jane Austen',\n",
       "  \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\",\n",
       "  ['humor', 'love', 'romantic', 'women']],\n",
       " ['J.K. Rowling',\n",
       "  '“Remember, if the time should come when you have to make a choice between what is right and what is easy, remember what happened to a boy who was good, and kind, and brave, because he strayed across the path of Lord Voldemort. Remember Cedric Diggory.”',\n",
       "  ['integrity']],\n",
       " ['Jane Austen',\n",
       "  '“I declare after all there is no enjoyment like reading! How much sooner one tires of any thing than of a book! -- When I have a house of my own, I shall be miserable if I have not an excellent library.”',\n",
       "  ['books', 'library', 'reading']],\n",
       " ['Jane Austen',\n",
       "  '“There are few people whom I really love, and still fewer of whom I think well. The more I see of the world, the more am I dissatisfied with it; and every day confirms my belief of the inconsistency of all human characters, and of the little dependence that can be placed on the appearance of merit or sense.”',\n",
       "  ['elizabeth-bennet', 'jane-austen']],\n",
       " ['C.S. Lewis',\n",
       "  '“Some day you will be old enough to start reading fairy tales again.”',\n",
       "  ['age', 'fairytales', 'growing-up']],\n",
       " ['C.S. Lewis',\n",
       "  '“We are not necessarily doubting that God will do the best for us; we are wondering how painful the best will turn out to be.”',\n",
       "  ['god']],\n",
       " ['Mark Twain',\n",
       "  '“The fear of death follows from the fear of life. A man who lives fully is prepared to die at any time.”',\n",
       "  ['death', 'life']],\n",
       " ['Mark Twain',\n",
       "  '“A lie can travel half way around the world while the truth is putting on its shoes.”',\n",
       "  ['misattributed-mark-twain', 'truth']],\n",
       " ['C.S. Lewis',\n",
       "  '“I believe in Christianity as I believe that the sun has risen: not only because I see it, but because by it I see everything else.”',\n",
       "  ['christianity', 'faith', 'religion', 'sun']],\n",
       " ['J.K. Rowling',\n",
       "  '“The truth.\" Dumbledore sighed. \"It is a beautiful and terrible thing, and should therefore be treated with great caution.”',\n",
       "  ['truth']],\n",
       " ['Jimi Hendrix',\n",
       "  \"“I'm the one that's got to die when it's time for me to die, so let me live my life the way I want to.”\",\n",
       "  ['death', 'life']],\n",
       " ['J.M. Barrie',\n",
       "  '“To die will be an awfully big adventure.”',\n",
       "  ['adventure', 'love']],\n",
       " ['E.E. Cummings',\n",
       "  '“It takes courage to grow up and become who you really are.”',\n",
       "  ['courage']],\n",
       " ['Khaled Hosseini',\n",
       "  '“But better to get hurt by the truth than comforted with a lie.”',\n",
       "  ['life']],\n",
       " ['Harper Lee',\n",
       "  '“You never really understand a person until you consider things from his point of view... Until you climb inside of his skin and walk around in it.”',\n",
       "  ['better-life-empathy']],\n",
       " [\"Madeleine L'Engle\",\n",
       "  '“You have to write the book that wants to be written. And if the book will be too difficult for grown-ups, then you write it for children.”',\n",
       "  ['books',\n",
       "   'children',\n",
       "   'difficult',\n",
       "   'grown-ups',\n",
       "   'write',\n",
       "   'writers',\n",
       "   'writing']],\n",
       " ['Mark Twain',\n",
       "  '“Never tell the truth to people who are not worthy of it.”',\n",
       "  ['truth']],\n",
       " ['Dr. Seuss',\n",
       "  \"“A person's a person, no matter how small.”\",\n",
       "  ['inspirational']],\n",
       " ['George R.R. Martin',\n",
       "  '“... a mind needs books as a sword needs a whetstone, if it is to keep its edge.”',\n",
       "  ['books', 'mind']]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas = []  # Haremos una lista de filas que añadir al dataframe que recoja los datos.\n",
    "\n",
    "\n",
    "for i in range(1,11):  # Para cada una de las diez páginas, desde la página 1 hasta la página 10...\n",
    "    url=\"https://quotes.toscrape.com/page/\" + str(i) + \"/\"\n",
    "    pagina = requests.get(url)\n",
    "    soup = BeautifulSoup(pagina.content, \"html.parser\")  # Como antes, usamos el paseador \"html\".\n",
    "    citas = soup.find_all('div', class_ = \"quote\")\n",
    "\n",
    "    for cita in citas:\n",
    "        registro = []\n",
    "        # Añadimos autor a una lista.\n",
    "        autor = cita.find(\"small\", class_ = \"author\").text.strip()\n",
    "        registro.append(autor)\n",
    "        \n",
    "        # Texto de la cita\n",
    "        texto_cita = cita.find(\"span\", class_ = \"text\", itemprop=\"text\").text.strip()\n",
    "        registro.append(texto_cita)\n",
    "        \n",
    "        # Añadiremos los tags como lista, porque son varios.\n",
    "        tags = [tag.text for tag in cita.find_all(\"a\", class_=\"tag\")]\n",
    "        registro.append(tags)\n",
    "        \n",
    "        filas.append(registro)\n",
    "    sleep(random.randint(1, 3))\n",
    "\n",
    "filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5859bfe1-5bee-4bf4-9aa9-d29c5212c0a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autor</th>\n",
       "      <th>Cita</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>[change, deep-thoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>[be-yourself, inspirational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "      <td>[better-life-empathy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Madeleine L'Engle</td>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "      <td>[books, children, difficult, grown-ups, write,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "      <td>[truth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>“A person's a person, no matter how small.”</td>\n",
       "      <td>[inspirational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>George R.R. Martin</td>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "      <td>[books, mind]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Autor                                               Cita  \\\n",
       "0      Albert Einstein  “The world as we have created it is a process ...   \n",
       "1         J.K. Rowling  “It is our choices, Harry, that show what we t...   \n",
       "2      Albert Einstein  “There are only two ways to live your life. On...   \n",
       "3          Jane Austen  “The person, be it gentleman or lady, who has ...   \n",
       "4       Marilyn Monroe  “Imperfection is beauty, madness is genius and...   \n",
       "..                 ...                                                ...   \n",
       "95          Harper Lee  “You never really understand a person until yo...   \n",
       "96   Madeleine L'Engle  “You have to write the book that wants to be w...   \n",
       "97          Mark Twain  “Never tell the truth to people who are not wo...   \n",
       "98           Dr. Seuss        “A person's a person, no matter how small.”   \n",
       "99  George R.R. Martin  “... a mind needs books as a sword needs a whe...   \n",
       "\n",
       "                                                 Tags  \n",
       "0            [change, deep-thoughts, thinking, world]  \n",
       "1                                [abilities, choices]  \n",
       "2      [inspirational, life, live, miracle, miracles]  \n",
       "3                  [aliteracy, books, classic, humor]  \n",
       "4                        [be-yourself, inspirational]  \n",
       "..                                                ...  \n",
       "95                              [better-life-empathy]  \n",
       "96  [books, children, difficult, grown-ups, write,...  \n",
       "97                                            [truth]  \n",
       "98                                    [inspirational]  \n",
       "99                                      [books, mind]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas_citas = ['Autor', 'Cita', 'Tags']\n",
    "df_citas = pd.DataFrame(filas, columns=columnas_citas)\n",
    "df_citas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3706ab-626a-400c-9d13-a3ca28a5f02b",
   "metadata": {},
   "source": [
    "¡Listo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c23ca-bc7a-40f1-beef-6b14c1c866da",
   "metadata": {},
   "source": [
    "### Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6a3b8-aea4-4cd0-b949-f31beda5b2b9",
   "metadata": {},
   "source": [
    "Abordamos ahora el scraping de la página de Wikipedia que recoge las películas en las que participó Carl Weathers, famoso por sus papeles como Apollo Creed en la saga \"Rocky\", y como Dillon (famosísima escena [Dillon, you son of a bitch!](https://www.youtube.com/watch?v=wLgsLDIFyA4) con \"Dutch\", Arnold Schwarzenegger) en \"Predator\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7d903-3290-40b7-9cb0-16b896633d79",
   "metadata": {},
   "source": [
    "Primero, instalación del webdriver correcto mediante DriverManager. De lo contrario, se encuentran muchos problemas, y las actualizaciones de navegador o driver pueden hacer que el código deje de funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "607743c1-c79e-4c04-a9ef-155b2401e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede ser necesario para asegurar que GitHub no bloquea las requests de webdriver manager (hay un límite)\n",
    "os.environ['GH_TOKEN'] = \"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\"   # Este token expira el día 1 de marzo.\n",
    "\n",
    "# Initialize the Firefox driver using webdriver-manager to handle the geckodriver\n",
    "# driver = webdriver.Firefox(executable_path=GeckoDriverManager().install()) # webdriver_manager instala automáticamente la versión compatible con mi navegador Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "531d8a64-ec1d-4fd3-8b2d-91d26ac6f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para averiguar dónde instaló WebdriverManager el driver: (y así no reinstalar cada vez)\n",
    "\n",
    "'''\n",
    "# Check if the geckodriver is already installed\n",
    "try:\n",
    "    driver_path = GeckoDriverManager().install()\n",
    "except:\n",
    "    # If it's already installed, retrieve the path without re-installing\n",
    "    driver_path = GeckoDriverManager().install_from_cache()\n",
    "\n",
    "# Initialize the Firefox driver using the stored driver path\n",
    "driver = webdriver.Firefox(executable_path=driver_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0978831-16f1-4871-b805-622c34a19869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\karel\\\\.wdm\\\\drivers\\\\geckodriver\\\\win64\\\\v0.34.0\\\\geckodriver.exe'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#driver_path  \n",
    "\n",
    "# Esto lo recupero después de instalar una vez mediante webdriver manager, para no instalar cada vez el driver.\n",
    "# El driver_path es: \"'C:\\\\Users\\\\karel\\\\.wdm\\\\drivers\\\\geckodriver\\\\win64\\\\v0.34.0\\\\geckodriver.exe'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14218b25-d99f-416a-a0b2-52b1fef4e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por lo tanto para no reinstalar el driver nos basta con anotar este \"path\" y aplicarlo así:\n",
    "driver = webdriver.Firefox(executable_path='C:\\\\Users\\\\karel\\\\.wdm\\\\drivers\\\\geckodriver\\\\win64\\\\v0.34.0\\\\geckodriver.exe')\n",
    "\n",
    "driver.get('https://es.wikipedia.org/wiki/Carl_Weathers')\n",
    "\n",
    "# Correcting the file path for Windows (if using local file)\n",
    "#file_path = r'C:\\Users\\karel\\IT Academy Data Science Notebooks\\estructures_Dataframe\\test_page_3.html'\n",
    "# Convert to an appropriate URL scheme for local files\n",
    "#file_url = 'file:///' + file_path.replace('\\\\', '/')\n",
    "#print(file_url)\n",
    "sleep(3)  # Para darle al driver tiempo a abrirse completamente.\n",
    "\n",
    "\n",
    "#driver.get(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e855e0a7-5b35-4340-bc7d-0b4342912131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=62508): Max retries exceeded with url: /session/343e7b3d-268c-46a2-af83-1dd8c062d672/element (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001ED7AF48B20>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connectionpool.py:416\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001ED7AF48B20>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m rows_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Buscamos una tabla en la página web, y más concretamente una tabla que tenga la característica style*=\"margin: 1em 1em 1em 0;\".\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtable[style*=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin: 1em 1em 1em 0;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Localizamos los elementos con el tag HTML \"tr\" (table row):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m rows \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mTAG_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:976\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m         by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    975\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:319\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    316\u001b[0m         params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m    318\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_value(params)\n\u001b[1;32m--> 319\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:374\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[0;32m    373\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url, path)\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:397\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    394\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 397\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\request.py:81\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     78\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\request.py:173\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    170\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    171\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connectionpool.py:827\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    826\u001b[0m     )\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    844\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connectionpool.py:827\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    826\u001b[0m     )\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    844\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connectionpool.py:827\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    826\u001b[0m     )\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    844\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SocketError, HTTPException)):\n\u001b[0;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8.13\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    581\u001b[0m new_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew(\n\u001b[0;32m    582\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[0;32m    583\u001b[0m     connect\u001b[38;5;241m=\u001b[39mconnect,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    589\u001b[0m )\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=62508): Max retries exceeded with url: /session/343e7b3d-268c-46a2-af83-1dd8c062d672/element (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001ED7AF48B20>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))"
     ]
    }
   ],
   "source": [
    "rows_data = []\n",
    "\n",
    "# Buscamos una tabla en la página web, y más concretamente una tabla que tenga la característica style*=\"margin: 1em 1em 1em 0;\".\n",
    "table = driver.find_element(By.CSS_SELECTOR, 'table[style*=\"margin: 1em 1em 1em 0;\"]')\n",
    "\n",
    "# Localizamos los elementos con el tag HTML \"tr\" (table row):\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# Extraemos de las \"rows\" la información:\n",
    "for row in rows:\n",
    "    # Celdas de la fila, es decir, \"table data\" (tag <td>):\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    # Extraemos el texto de cada celda y lo añadimos a row_info:\n",
    "    row_info = [cell.text for cell in cells]\n",
    "    if row_info:  # \n",
    "        rows_data.append(row_info)\n",
    "\n",
    "# Convert the list of rows into a pandas DataFrame\n",
    "df = pd.DataFrame(rows_data, columns=['Año', 'Título', 'Papel'])\n",
    "\n",
    "# Clean up by closing the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# NOTA: al volver a ejecutar el código me bloqueó (pero ya se habían descargado los datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e927232-d237-42a5-a033-f1f9b2b49367",
   "metadata": {},
   "source": [
    "Hay que tener cuidado para evitar los bloqueos...! Igualmente, en la anterior ejecución de la celda ya logramos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcee1aae-7739-4207-9df9-e7231f6e3c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Título</th>\n",
       "      <th>Papel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Año</td>\n",
       "      <td>Título</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>Kung Fu</td>\n",
       "      <td>Sam el Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975</td>\n",
       "      <td>Friday Foster</td>\n",
       "      <td>Yarbro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>Rocky</td>\n",
       "      <td>Apollo Creed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977</td>\n",
       "      <td>Encuentros cercanos del tercer tipo (Latinoamé...</td>\n",
       "      <td>Policía Militar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1976</td>\n",
       "      <td>Fuerza 10 de Navarone</td>\n",
       "      <td>Weaver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1978</td>\n",
       "      <td>Los abismos de las Bermudas</td>\n",
       "      <td>Eric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1979</td>\n",
       "      <td>Rocky II</td>\n",
       "      <td>Apollo Creed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1981</td>\n",
       "      <td>Death Hunt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1982</td>\n",
       "      <td>Rocky III</td>\n",
       "      <td>Apollo Creed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1985</td>\n",
       "      <td>Rocky IV</td>\n",
       "      <td>Apollo Creed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1986</td>\n",
       "      <td>Fortune Dane</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1987</td>\n",
       "      <td>Depredador</td>\n",
       "      <td>Dillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1988</td>\n",
       "      <td>Action Jackson</td>\n",
       "      <td>Sargento Jericho 'Action' Jackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1990</td>\n",
       "      <td>Dangerous Passion</td>\n",
       "      <td>Kyle Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1989-1990</td>\n",
       "      <td>Nam, Primer Pelotón</td>\n",
       "      <td>Coronel Brewster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1990</td>\n",
       "      <td>Rocky V</td>\n",
       "      <td>Apollo Creed (flashback)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1991-1993</td>\n",
       "      <td>Street Justice</td>\n",
       "      <td>Adam Beaudreaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1995</td>\n",
       "      <td>OP Center</td>\n",
       "      <td>General Mike Rodgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1993-1995</td>\n",
       "      <td>In the Heat of the Night</td>\n",
       "      <td>Jefe Hampton Forbes / Inspector Hampton Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1996</td>\n",
       "      <td>Happy Gilmore / Terminagolf (España)</td>\n",
       "      <td>Chubbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1997</td>\n",
       "      <td>Asalto a la Isla del Diablo</td>\n",
       "      <td>Roy Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1999</td>\n",
       "      <td>Shadow Warriors II: Hunt for the Death Merchant</td>\n",
       "      <td>Roy Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1999</td>\n",
       "      <td>Elevator Seeking</td>\n",
       "      <td>William</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ocho noches de locura</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2005</td>\n",
       "      <td>Alien Siege</td>\n",
       "      <td>General Skyler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2007</td>\n",
       "      <td>The Comebacks</td>\n",
       "      <td>Freddie Wiseman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2008</td>\n",
       "      <td>Oh, hermano - Urgencias (Temporada 15, Episodi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2004-2013</td>\n",
       "      <td>Arrested Development</td>\n",
       "      <td>Carl Weathers (versión ficticia de sí mismo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2011-2013</td>\n",
       "      <td>Un show más</td>\n",
       "      <td>Dios del basquetbol (voz)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013</td>\n",
       "      <td>Toy Story of Terror</td>\n",
       "      <td>Combat Carl (voz)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2014</td>\n",
       "      <td>Think Like a Man Too</td>\n",
       "      <td>Mr. Davenport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2015</td>\n",
       "      <td>Creed</td>\n",
       "      <td>Apollo Creed (flashbacks, escenas de combate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2016</td>\n",
       "      <td>Colony</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chicago Justice</td>\n",
       "      <td>Mark Jefferies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018</td>\n",
       "      <td>Creed II</td>\n",
       "      <td>Apollo Creed (flashbacks, escenas de combate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>The Mandalorian</td>\n",
       "      <td>Greef Karga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>Toy Story 4</td>\n",
       "      <td>Combate Carl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Año                                             Título  \\\n",
       "0         Año                                             Título   \n",
       "1        1975                                            Kung Fu   \n",
       "2        1975                                      Friday Foster   \n",
       "3        1976                                              Rocky   \n",
       "4        1977  Encuentros cercanos del tercer tipo (Latinoamé...   \n",
       "5        1976                              Fuerza 10 de Navarone   \n",
       "6        1978                        Los abismos de las Bermudas   \n",
       "7        1979                                           Rocky II   \n",
       "8        1981                                         Death Hunt   \n",
       "9        1982                                          Rocky III   \n",
       "10       1985                                           Rocky IV   \n",
       "11       1986                                       Fortune Dane   \n",
       "12       1987                                         Depredador   \n",
       "13       1988                                     Action Jackson   \n",
       "14       1990                                  Dangerous Passion   \n",
       "15  1989-1990                                Nam, Primer Pelotón   \n",
       "16       1990                                            Rocky V   \n",
       "17  1991-1993                                     Street Justice   \n",
       "18       1995                                          OP Center   \n",
       "19  1993-1995                           In the Heat of the Night   \n",
       "20       1996               Happy Gilmore / Terminagolf (España)   \n",
       "21       1997                        Asalto a la Isla del Diablo   \n",
       "22       1999    Shadow Warriors II: Hunt for the Death Merchant   \n",
       "23       1999                                   Elevator Seeking   \n",
       "24       2002                              Ocho noches de locura   \n",
       "25       2005                                        Alien Siege   \n",
       "26       2007                                      The Comebacks   \n",
       "27       2008  Oh, hermano - Urgencias (Temporada 15, Episodi...   \n",
       "28  2004-2013                               Arrested Development   \n",
       "29  2011-2013                                        Un show más   \n",
       "30       2013                                Toy Story of Terror   \n",
       "31       2014                               Think Like a Man Too   \n",
       "32       2015                                              Creed   \n",
       "33       2016                                             Colony   \n",
       "34       2017                                    Chicago Justice   \n",
       "35       2018                                           Creed II   \n",
       "36       2019                                    The Mandalorian   \n",
       "37       2019                                        Toy Story 4   \n",
       "\n",
       "                                                Papel  \n",
       "0                                               Papel  \n",
       "1                                         Sam el Malo  \n",
       "2                                              Yarbro  \n",
       "3                                        Apollo Creed  \n",
       "4                                     Policía Militar  \n",
       "5                                              Weaver  \n",
       "6                                                Eric  \n",
       "7                                        Apollo Creed  \n",
       "8                                                      \n",
       "9                                        Apollo Creed  \n",
       "10                                       Apollo Creed  \n",
       "11                                                     \n",
       "12                                             Dillon  \n",
       "13                  Sargento Jericho 'Action' Jackson  \n",
       "14                                       Kyle Western  \n",
       "15                                   Coronel Brewster  \n",
       "16                           Apollo Creed (flashback)  \n",
       "17                                    Adam Beaudreaux  \n",
       "18                               General Mike Rodgers  \n",
       "19     Jefe Hampton Forbes / Inspector Hampton Forbes  \n",
       "20                                             Chubbs  \n",
       "21                                          Roy Brown  \n",
       "22                                          Roy Brown  \n",
       "23                                            William  \n",
       "24                                                     \n",
       "25                                     General Skyler  \n",
       "26                                    Freddie Wiseman  \n",
       "27                                                     \n",
       "28       Carl Weathers (versión ficticia de sí mismo)  \n",
       "29                          Dios del basquetbol (voz)  \n",
       "30                                  Combat Carl (voz)  \n",
       "31                                      Mr. Davenport  \n",
       "32  Apollo Creed (flashbacks, escenas de combate c...  \n",
       "33                                                     \n",
       "34                                     Mark Jefferies  \n",
       "35  Apollo Creed (flashbacks, escenas de combate c...  \n",
       "36                                        Greef Karga  \n",
       "37                                       Combate Carl  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909b311-be40-47f5-835f-eca6c6168797",
   "metadata": {},
   "source": [
    "Después de hecho el ejercicio probando dos herramientas diferentes, puedo decir que por un lado BeautifulSoup es más sencillo lograr que funcione \"out of the box\", dado que tiene menos complicación técncia/configuración. Selenium puede dar más problemas en ese sentido (hasta que se descubre WebdriverManager) ya que los webdrivers necesitan coincidir con la versión de navegador que se está usando.\n",
    "\n",
    "Cabe añadir otra cosa. El ejemplo de wikipedia seleccionado sobre Carl Weathers era relativamente sencillo, pero antes he podido comprobar en carne propia que eso no siempre es así. Las webs tipo \"wiki\", basadas en contribuciones de una comunidad diversa, pueden no seguir siempre los mismos criterios de formato/estructura HTML, dificultando un scraping coherente de toda la información de interés (motivo por el que descarté otra página y me decidí finalmente por la de Carl Weathers que tenía elementos sin \"caos\"...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654fc7c1-4a5b-4d74-90b3-e881652727c7",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Documentar en un archivo Word el conjunto de datos generado antes, con la información al estilo de la de los ficheros de datos de Kaggle (como por ejemplo este dataset de Kaggle: https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aede4ba-db50-40bc-ad8c-5871bf1d3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver en repositorio del ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a96c2-ac4d-418b-879f-aef2b85082ca",
   "metadata": {},
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "Elegir una página web y realizar web scraping primero mediante Selenium y luego mediante Scrapy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c949fb-35a8-445f-bf4b-9ac3a01d0094",
   "metadata": {},
   "source": [
    "### Selección web: Ground News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81ddf4-b60a-4b67-9020-5468dc434d18",
   "metadata": {},
   "source": [
    "Trabajaré con la web de Ground News, que recopila y clasifica las noticias de diversos medios de comunicación, y que preveo trabajar de cara al proyecto final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dadc98bd-4954-4e76-ad6a-2d90df75ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path='C:\\\\Users\\\\karel\\\\.wdm\\\\drivers\\\\geckodriver\\\\win64\\\\v0.34.0\\\\geckodriver.exe')\n",
    "#driver.get(url)\n",
    "\n",
    "url = \"https://ground.news/\"\n",
    "\n",
    "# Lo que sigue es una forma de hacer los tests con un fichero en local y... ¡evitar el bloqueo durante el aprendizaje de cómo usar la herramienta...!!\n",
    "# Solo usado para tests, pero lo dejo indicado aquí, ya que reutilizaré este procedimiento\n",
    "# file_path = r'C:\\Users\\karel\\Desktop\\Webs\\Breaking News Headlines and Media Bias Ground News.htm'\n",
    "# file_url = 'file:///' + file_path.replace('\\\\', '/')\n",
    "# print(file_url)\n",
    "# driver.get(file_url)\n",
    "\n",
    "\n",
    "sleep(3)  # Para darle al driver tiempo a abrirse completamente.\n",
    "\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6849073b-f406-40eb-a34b-d2c997a61105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que clicar y responder (preferiblemente) al botón de \"Manage Cookies\".\n",
    "# Nos basamos en el texto del botón (\"Manage Cookies\"), que en principio es único, no ha de aparecer en otro lugar de la página.\n",
    "\n",
    "# Espera a que el botón con texto \"Manage cookies\" aparezca y sea clicable.\n",
    "manage_cookies_button = WebDriverWait(driver, 10).until(   # 10 seg, máximo tiempo de espera.\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Manage cookies')]\"))  \n",
    ")\n",
    "manage_cookies_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f19c3011-a417-4a4f-85ed-c1e93a1da376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click al botón \"Save & reload\" (esto deja solo las cookies técnicas)\n",
    "save_cookies_button = WebDriverWait(driver, 10).until(   # 10 seg, máximo tiempo de espera.\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Save & reload')]\"))  # Espera a que el botón con texto \"Manage cookies\" sea clicable.\n",
    ")\n",
    "save_cookies_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f460200-e26d-4bd0-a01c-b30b8d157c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop-up closed.\n",
      "No pop-up appeared.\n",
      "Pop-up closed.\n",
      "No pop-up appeared.\n",
      "Pop-up closed.\n",
      "No pop-up appeared.\n",
      "No more 'More stories' button found or page took too long to load.\n"
     ]
    }
   ],
   "source": [
    "def cerrar_popup():  # Hay un pop-up que aparece cada tres veces aproximadamente que se le da al botón \"More Stories\". Para cerrarlo.\n",
    "    try:\n",
    "        wait_time = random.uniform(2.5, 4.5)\n",
    "        close_button = WebDriverWait(driver, wait_time).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, \"react-responsive-modal-closeButton\"))\n",
    "        )\n",
    "        close_button.click()\n",
    "        print(\"Pop-up closed.\")   # Hay un pop-up que aparece cada tres veces aproximadamente que se le da al botón \"More Stories\". Lo cerramos.\n",
    "    except TimeoutException:\n",
    "        print(\"No pop-up appeared.\")\n",
    "\n",
    "def click_more_stories():   # Función para que se nos muestren más noticias al pulsar el botón \"More stories\".\n",
    "    while True:\n",
    "        try:\n",
    "            more_stories_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'More stories')]\"))\n",
    "            )\n",
    "            wait_time = random.uniform(0.9, 3.4)\n",
    "            time.sleep(wait_time)\n",
    "            more_stories_button.click()\n",
    "            cerrar_popup()   # Si aparece, cerramos el pop-up que aparece cada ciertos clicks a \"More stories\".\n",
    "        except TimeoutException:\n",
    "            print(\"No more 'More stories' button found or page took too long to load.\")\n",
    "            break  # Exiting the loop if \"More stories\" button is no longer found\n",
    "\n",
    "\n",
    "# Example usage\n",
    "click_more_stories() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6269f36-6b49-4a48-b35c-cd35cb00b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump does not have presidential immunity in January 6 case, federal appeals court rules\n",
      "Georgia says it seized Russia-bound cargo of explosives sent from Ukraine\n",
      "Orbán boycotts parliament session called to ratify Swedish Nato bid\n",
      "Spanish league to denounce fan who touched player’s backside during game\n",
      "Journalists say Ukrainian security service spied on them\n",
      "Taylor Swift threatens legal action against student who tracks her jet\n",
      "Home Secretary ‘to look at’ claims forty Bibby Stockholm migrants are converting to Christianity\n",
      "How climate change contributes to wildfires like Chile's\n",
      "Cannabis use linked to anxiety diagnoses, worsened anxiety disorders: Ontario study\n",
      "King Charles III diagnosed with cancer, Buckingham Palace says\n",
      "NASA discovers 'super-Earth' 137-light years away in a habitable zone that could sustain life\n",
      "US would redirect aid from UNRWA to other agencies under Senate bill - State Dept\n",
      "Arab American leaders demand apology, retraction after Wall Street Journal 'jihad' column\n",
      "Senate Minority Leader Mitch McConnell Signals Retreat From Border Bill\n",
      "UN nuclear chief says security is still fragile at Ukraine's Russian-occupied nuclear power plant\n",
      "Spain says over 1,000 migrants reached its Canary Islands in 3 days as more attempt deadly crossing\n",
      "EU calls for 90 percent emissions cut by 2040\n",
      "Russian court arrests fiction writer in absentia on charges of incitement to terrorism\n",
      "China economy overtaking U.S. is increasingly unlikely: ex-IMF official\n",
      "EU scraps pesticide proposals in another concession to protesting farmers\n",
      "Liz Truss claims ‘left-wing extremists’ have taken over UK institutions as she launches Popular Conservatives\n",
      "Spanish farmers blockade roads, joining EU peers' protests\n",
      "Turkey mourns tens of thousands dead, surrounded by the ruins of last year’s earthquake\n",
      "Palantir stock jumps 12% on revenue beat\n",
      "UBS to Restart Buybacks This Year as It Integrates Credit Suisse\n",
      "AI helps scholars read scroll buried when Vesuvius erupted in AD79\n",
      "Germany doubles its commitment of troops to the NATO-led peacekeepers in Kosovo\n",
      "Iranian agents suspected of targeting Jews arrested in Sweden, deported\n",
      "California could legalize psychedelic therapy after rejecting ‘magic mushroom’ decriminalization\n",
      "Putin will visit Turkey soon to discuss new Black Sea grain export ideas for Ukraine, minister says\n",
      "Facebook and Instagram to label all images on its platforms created by AI, Meta says\n",
      "More Than One In Five Remaining Israeli Hostages In Gaza Are Dead, Report Says\n",
      "Scientists propose a Category 6 as hurricanes gain in intensity with climate change\n"
     ]
    }
   ],
   "source": [
    "# Titular principal\n",
    "highlighted_title_element = driver.find_elements(By.CSS_SELECTOR, 'a.relative.flex.flex-col.cursor-pointer h2')\n",
    "\n",
    "# Otras noticias\n",
    "general_titles_elements = driver.find_elements(By.CSS_SELECTOR, 'h4[class*=\"font-bold\"]')\n",
    "\n",
    "# Combinar ambos\n",
    "all_titles_elements = highlighted_title_element + general_titles_elements\n",
    "\n",
    "# Convertir a \"set\" y luego convertir en lista logra eliminar repeticiones; \"strip\" también ayuda a limpiar espacios superfluos.\n",
    "news_titles = list(set([title.text.strip() for title in all_titles_elements if title.text.strip()]))\n",
    "\n",
    "# Resultados\n",
    "for title in news_titles:\n",
    "    print(title)\n",
    "\n",
    "# Cierre del \"driver\"\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cab7c61-121b-4844-9169-7df242671831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_titles)  # Hemos recogido los títulos de 33 noticias, sin repeticiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67d89b3f-69de-4dbc-af42-134615c92721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trump does not have presidential immunity in January 6 case, federal appeals court rules',\n",
       " 'Georgia says it seized Russia-bound cargo of explosives sent from Ukraine',\n",
       " 'Orbán boycotts parliament session called to ratify Swedish Nato bid',\n",
       " 'Spanish league to denounce fan who touched player’s backside during game',\n",
       " 'Journalists say Ukrainian security service spied on them',\n",
       " 'Taylor Swift threatens legal action against student who tracks her jet',\n",
       " 'Home Secretary ‘to look at’ claims forty Bibby Stockholm migrants are converting to Christianity',\n",
       " \"How climate change contributes to wildfires like Chile's\",\n",
       " 'Cannabis use linked to anxiety diagnoses, worsened anxiety disorders: Ontario study',\n",
       " 'King Charles III diagnosed with cancer, Buckingham Palace says',\n",
       " \"NASA discovers 'super-Earth' 137-light years away in a habitable zone that could sustain life\",\n",
       " 'US would redirect aid from UNRWA to other agencies under Senate bill - State Dept',\n",
       " \"Arab American leaders demand apology, retraction after Wall Street Journal 'jihad' column\",\n",
       " 'Senate Minority Leader Mitch McConnell Signals Retreat From Border Bill',\n",
       " \"UN nuclear chief says security is still fragile at Ukraine's Russian-occupied nuclear power plant\",\n",
       " 'Spain says over 1,000 migrants reached its Canary Islands in 3 days as more attempt deadly crossing',\n",
       " 'EU calls for 90 percent emissions cut by 2040',\n",
       " 'Russian court arrests fiction writer in absentia on charges of incitement to terrorism',\n",
       " 'China economy overtaking U.S. is increasingly unlikely: ex-IMF official',\n",
       " 'EU scraps pesticide proposals in another concession to protesting farmers',\n",
       " 'Liz Truss claims ‘left-wing extremists’ have taken over UK institutions as she launches Popular Conservatives',\n",
       " \"Spanish farmers blockade roads, joining EU peers' protests\",\n",
       " 'Turkey mourns tens of thousands dead, surrounded by the ruins of last year’s earthquake',\n",
       " 'Palantir stock jumps 12% on revenue beat',\n",
       " 'UBS to Restart Buybacks This Year as It Integrates Credit Suisse',\n",
       " 'AI helps scholars read scroll buried when Vesuvius erupted in AD79',\n",
       " 'Germany doubles its commitment of troops to the NATO-led peacekeepers in Kosovo',\n",
       " 'Iranian agents suspected of targeting Jews arrested in Sweden, deported',\n",
       " 'California could legalize psychedelic therapy after rejecting ‘magic mushroom’ decriminalization',\n",
       " 'Putin will visit Turkey soon to discuss new Black Sea grain export ideas for Ukraine, minister says',\n",
       " 'Facebook and Instagram to label all images on its platforms created by AI, Meta says',\n",
       " 'More Than One In Five Remaining Israeli Hostages In Gaza Are Dead, Report Says',\n",
       " 'Scientists propose a Category 6 as hurricanes gain in intensity with climate change']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a602f3aa-2843-478d-984e-3c45954188a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump does not have presidential immunity in J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Georgia says it seized Russia-bound cargo of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orbán boycotts parliament session called to ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spanish league to denounce fan who touched pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Journalists say Ukrainian security service spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  Trump does not have presidential immunity in J...\n",
       "1  Georgia says it seized Russia-bound cargo of e...\n",
       "2  Orbán boycotts parliament session called to ra...\n",
       "3  Spanish league to denounce fan who touched pla...\n",
       "4  Journalists say Ukrainian security service spi..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the 'titles' column\n",
    "df = pd.DataFrame({'title': news_titles})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3cbf8-3c0e-41a4-87f6-55b79e35f7f0",
   "metadata": {},
   "source": [
    "En esta ocasión hemos hecho un scraping levemente más complejo, en el sentido de que le hemos dicho al \"driver\" que interactúe con la web y ejecute algunas acciones (pulsar diversos botones y esperar que se desplieguen elementos en la página) y que nos permiten descargar algunos datos extra. Añadiremos complejidad en el proyecto, por ejemplo en la cuestión de extraer datos referidos al \"alineamiento\" político de los medios (izquierda, centro o derecha) y a qué tipo de noticias cubren o no, es decir, cuáles son los \"blind spots\" (temas invisibles) para medios de uno u otro lado del espectro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3071a-3568-4705-8493-0152e43cda23",
   "metadata": {},
   "source": [
    "Veamos ahora el scraping mediante \"Scrapy\". Lo hacemos fuera de Jupyter pero describo el proceso aquí. Abrimos un terminal y corremos el siguiente comando, después de instalar scrapy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95901c46-0778-4b52-988f-e05653c31197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (py3.8.13) C:\\Users\\karel\\IT Academy Data Science Notebooks\\estructures_Dataframe>scrapy startproject ground_news_scrapy\n",
    "'''\n",
    "New Scrapy project 'ground_news_scrapy', using template directory 'C:\\Users\\karel\\anaconda3\\envs\\py3.8.13\\Lib\\site-packages\\scrapy\\templates\\project', created in:\n",
    "    C:\\Users\\karel\\IT Academy Data Science Notebooks\\estructures_Dataframe\\ground_news_scrapy\n",
    "\n",
    "You can start your first spider with:\n",
    "    cd ground_news_scrapy\n",
    "    scrapy genspider example example.com\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21075fd7-3d5e-4bee-9bd5-df1e2482f946",
   "metadata": {},
   "source": [
    "En la ubicación en que ejecutemos el comando, lo anterior genera una serie de carpetas con la siguiente jerarquía, y con una serie de archivos de configuración y necesarios para ejecutar scrapy:\n",
    "\n",
    "ground_news_scrapy > ground_news_scrapy > spiders\n",
    "\n",
    "En la carpeta \"spiders\" hemos de crear un fichero de script de python que será una \"araña\" que nos servirá para escrapear. Este es su contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05e3b85e-72c9-4d05-a9db-436802cb6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contenido de la araña \"ground_news.py\" ubicada en la carpeta \"spiders\" del proyecto \"ground_news_scrapy\":\n",
    "\n",
    "import scrapy\n",
    "\n",
    "class NewsSpider(scrapy.Spider):\n",
    "    name = 'ground_news'\n",
    "    allowed_domains = ['ground.news']\n",
    "    start_urls = ['https://ground.news/'] # Change to the actual URL\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Selecting general news titles\n",
    "        for title in response.css('h4[class*=\"font-bold\"]::text').getall():\n",
    "            yield {'title': title.strip()}\n",
    "\n",
    "        # Selecting the highlighted news title\n",
    "        for title in response.css('a.relative.flex.flex-col.cursor-pointer h2::text').getall():\n",
    "            yield {'title': title.strip()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a0040-3286-4c09-a72c-b12a4369f99b",
   "metadata": {},
   "source": [
    "De entre los ficheros que se incluyen en el sistema de carpetas, hay alguno cuya configuración nos conviene considerar. En particular, nos interesa asegurarnos que la araña tiene un comportamiento poco agresivo para que no sea bloqueada. Para ello, modificamos el fichero \"settings.py\" que hay en la carpeta jerárquicamente intermedia \"ground_news_scrapy\".\n",
    "\n",
    "El contenido de dicho fichero \"settings.py\" que hemos decidido es este, fundamentalmente tratando de que la araña no se comporte de forma agresiva, para no ser bloqueada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02b552-0870-42ec-916c-1fd36b6ae420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapy settings.py content for ground_news_scrapy project\n",
    "#\n",
    "# For simplicity, this file contains only settings considered important or\n",
    "# commonly used. You can find more settings consulting the documentation:\n",
    "#\n",
    "#     https://docs.scrapy.org/en/latest/topics/settings.html\n",
    "#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n",
    "#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n",
    "\n",
    "BOT_NAME = \"ground_news_scrapy\"  # Nombre de la araña a utilizar\n",
    "\n",
    "SPIDER_MODULES = [\"ground_news_scrapy.spiders\"]\n",
    "NEWSPIDER_MODULE = \"ground_news_scrapy.spiders\"\n",
    "\n",
    "\n",
    "# Crawl responsibly by identifying yourself (and your website) on the user-agent\n",
    "#USER_AGENT = \"ground_news_scrapy (+http://www.yourdomain.com)\"\n",
    "\n",
    "# Obey robots.txt rules\n",
    "# Es importante, adecuado y buena práctica seguir la directiva del fichero \"robots.txt\" que tenga la web. Si no quieren bots, cumplid con ello.\n",
    "ROBOTSTXT_OBEY = True   \n",
    "\n",
    "# Configure maximum concurrent requests performed by Scrapy (default: 16)\n",
    "#CONCURRENT_REQUESTS = 32\n",
    "\n",
    "# Configure a delay for requests for the same website (default: 0)\n",
    "# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n",
    "# See also autothrottle settings and docs\n",
    "DOWNLOAD_DELAY = 3\n",
    "# The download delay setting will honor only one of:\n",
    "CONCURRENT_REQUESTS_PER_DOMAIN = 16\n",
    "#CONCURRENT_REQUESTS_PER_IP = 16\n",
    "\n",
    "# Disable cookies (enabled by default)\n",
    "#COOKIES_ENABLED = False\n",
    "\n",
    "# Disable Telnet Console (enabled by default)\n",
    "#TELNETCONSOLE_ENABLED = False\n",
    "\n",
    "# Override the default request headers:\n",
    "#DEFAULT_REQUEST_HEADERS = {\n",
    "#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "#    \"Accept-Language\": \"en\",\n",
    "#}\n",
    "\n",
    "# Enable or disable spider middlewares\n",
    "# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n",
    "#SPIDER_MIDDLEWARES = {\n",
    "#    \"ground_news_scrapy.middlewares.GroundNewsScrapySpiderMiddleware\": 543,\n",
    "#}\n",
    "\n",
    "# Enable or disable downloader middlewares\n",
    "# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n",
    "#DOWNLOADER_MIDDLEWARES = {\n",
    "#    \"ground_news_scrapy.middlewares.GroundNewsScrapyDownloaderMiddleware\": 543,\n",
    "#}\n",
    "\n",
    "# Enable or disable extensions\n",
    "# See https://docs.scrapy.org/en/latest/topics/extensions.html\n",
    "#EXTENSIONS = {\n",
    "#    \"scrapy.extensions.telnet.TelnetConsole\": None,\n",
    "#}\n",
    "\n",
    "# Configure item pipelines\n",
    "# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "#ITEM_PIPELINES = {\n",
    "#    \"ground_news_scrapy.pipelines.GroundNewsScrapyPipeline\": 300,\n",
    "#}\n",
    "\n",
    "# Enable and configure the AutoThrottle extension (disabled by default)\n",
    "# See https://docs.scrapy.org/en/latest/topics/autothrottle.html\n",
    "AUTOTHROTTLE_ENABLED = True\n",
    "# The initial download delay\n",
    "AUTOTHROTTLE_START_DELAY = 5\n",
    "# The maximum download delay to be set in case of high latencies\n",
    "AUTOTHROTTLE_MAX_DELAY = 60\n",
    "# The average number of requests Scrapy should be sending in parallel to\n",
    "# each remote server\n",
    "AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n",
    "# Enable showing throttling stats for every response received:\n",
    "#AUTOTHROTTLE_DEBUG = False\n",
    "\n",
    "# Enable and configure HTTP caching (disabled by default)\n",
    "# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n",
    "#HTTPCACHE_ENABLED = True\n",
    "#HTTPCACHE_EXPIRATION_SECS = 0\n",
    "#HTTPCACHE_DIR = \"httpcache\"\n",
    "#HTTPCACHE_IGNORE_HTTP_CODES = []\n",
    "#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n",
    "\n",
    "# Set settings whose default value is deprecated to a future-proof value\n",
    "REQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\n",
    "TWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\n",
    "FEED_EXPORT_ENCODING = \"utf-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749571de-afc2-4f04-a036-f9aed6dd3a21",
   "metadata": {},
   "source": [
    "Finalment, para correr scrapy hay que acceder a la carpeta ground_news_scrapy jerárquicamente superior (la primera). El comando, de modo que nos dé un fichero de datos .json como \"output\", es el siguiente:\n",
    "\n",
    "scrapy crawl ground_news -o output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90100a03-5453-4983-8f65-9335b3671663",
   "metadata": {},
   "outputs": [],
   "source": [
    "(py3.8.13) C:\\Users\\karel\\IT Academy Data Science Notebooks\\estructures_Dataframe\\ground_news_scrapy>scrapy crawl ground_news -o output06_02_2024.json\n",
    "2024-02-06 18:40:27 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: ground_news_scrapy)\n",
    "2024-02-06 18:40:27 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.8.13 (default, Oct 19 2022, 22:38:03) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 1.1.1w  11 Sep 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0\n",
    "2024-02-06 18:40:27 [scrapy.crawler] INFO: Overridden settings:\n",
    "{'AUTOTHROTTLE_ENABLED': True,\n",
    " 'BOT_NAME': 'ground_news_scrapy',\n",
    " 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,\n",
    " 'DOWNLOAD_DELAY': 3,\n",
    " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
    " 'NEWSPIDER_MODULE': 'ground_news_scrapy.spiders',\n",
    " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
    " 'ROBOTSTXT_OBEY': True,\n",
    " 'SPIDER_MODULES': ['ground_news_scrapy.spiders'],\n",
    " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
    "2024-02-06 18:40:27 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "2024-02-06 18:40:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
    "2024-02-06 18:40:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop\n",
    "2024-02-06 18:40:27 [scrapy.extensions.telnet] INFO: Telnet Password: fb9552ba259c0318\n",
    "2024-02-06 18:40:27 [scrapy.middleware] INFO: Enabled extensions:\n",
    "['scrapy.extensions.corestats.CoreStats',\n",
    " 'scrapy.extensions.telnet.TelnetConsole',\n",
    " 'scrapy.extensions.feedexport.FeedExporter',\n",
    " 'scrapy.extensions.logstats.LogStats',\n",
    " 'scrapy.extensions.throttle.AutoThrottle']\n",
    "2024-02-06 18:40:27 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
    "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
    " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
    " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
    " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
    " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
    " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
    " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
    "2024-02-06 18:40:27 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
    "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
    " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
    " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
    " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
    " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
    "2024-02-06 18:40:27 [scrapy.middleware] INFO: Enabled item pipelines:\n",
    "[]\n",
    "2024-02-06 18:40:27 [scrapy.core.engine] INFO: Spider opened\n",
    "2024-02-06 18:40:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
    "2024-02-06 18:40:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
    "2024-02-06 18:40:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ground.news/robots.txt> (referer: None)\n",
    "2024-02-06 18:40:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ground.news/> (referer: None)\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'EU calls for 90 percent emissions cut by 2040'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'EU scraps pesticide proposals in another concession to protesting farmers'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Georgia says it seized Russia-bound cargo of explosives sent from Ukraine'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'King Charles III diagnosed with cancer, Buckingham Palace says'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Orbán boycotts parliament session called to ratify Swedish Nato bid'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Cannabis use linked to anxiety diagnoses, worsened anxiety disorders: Ontario study'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"Spanish farmers blockade roads, joining EU peers' protests\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'AI helps scholars read scroll buried when Vesuvius erupted in AD79'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Taylor Swift threatens legal action against student who tracks her jet'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Iranian agents suspected of targeting Jews arrested in Sweden, deported'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Spanish league to denounce fan who touched player’s backside during game'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Facebook and Instagram to label all images on its platforms created by AI, Meta says'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"UN nuclear chief says security is still fragile at Ukraine's Russian-occupied nuclear power plant\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Journalists say Ukrainian security service spied on them'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'EU calls for 90 percent emissions cut by 2040'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'EU scraps pesticide proposals in another concession to protesting farmers'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Georgia says it seized Russia-bound cargo of explosives sent from Ukraine'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'King Charles III diagnosed with cancer, Buckingham Palace says'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Orbán boycotts parliament session called to ratify Swedish Nato bid'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Argentina president Javier Milei says plans to move embassy to Jerusalem'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'California could legalize psychedelic therapy after rejecting ‘magic mushroom’ decriminalization'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'AI helps scholars read scroll buried when Vesuvius erupted in AD79'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Taylor Swift threatens legal action against student who tracks her jet'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Iranian agents suspected of targeting Jews arrested in Sweden, deported'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Spanish league to denounce fan who touched player’s backside during game'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Spanish league to denounce fan who touched player’s backside during game'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Facebook and Instagram to label all images on its platforms created by AI, Meta says'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"UN nuclear chief says security is still fragile at Ukraine's Russian-occupied nuclear power plant\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Journalists say Ukrainian security service spied on them'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Russian court arrests fiction writer in absentia on charges of incitement to terrorism'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Facebook and Instagram to label all images on its platforms created by AI, Meta says'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"UN nuclear chief says security is still fragile at Ukraine's Russian-occupied nuclear power plant\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Journalists say Ukrainian security service spied on them'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Russian court arrests fiction writer in absentia on charges of incitement to terrorism'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'China economy overtaking U.S. is increasingly unlikely: ex-IMF official'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Russian court arrests fiction writer in absentia on charges of incitement to terrorism'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'China economy overtaking U.S. is increasingly unlikely: ex-IMF official'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Turkey mourns tens of thousands dead, surrounded by the ruins of last year’s earthquake'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'UBS to Restart Buybacks This Year as It Integrates Credit Suisse'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"NASA discovers 'super-Earth' 137-light years away in a habitable zone that could sustain life\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'China economy overtaking U.S. is increasingly unlikely: ex-IMF official'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Turkey mourns tens of thousands dead, surrounded by the ruins of last year’s earthquake'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'UBS to Restart Buybacks This Year as It Integrates Credit Suisse'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"NASA discovers 'super-Earth' 137-light years away in a habitable zone that could sustain life\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Germany doubles its commitment of troops to the NATO-led peacekeepers in Kosovo'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Turkey mourns tens of thousands dead, surrounded by the ruins of last year’s earthquake'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'UBS to Restart Buybacks This Year as It Integrates Credit Suisse'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"NASA discovers 'super-Earth' 137-light years away in a habitable zone that could sustain life\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Germany doubles its commitment of troops to the NATO-led peacekeepers in Kosovo'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Germany doubles its commitment of troops to the NATO-led peacekeepers in Kosovo'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': \"How climate change contributes to wildfires like Chile's\"}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Putin will visit Turkey soon to discuss new Black Sea grain export ideas for Ukraine, minister says'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Scientists propose a Category 6 as hurricanes gain in intensity with climate change'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Palantir stock jumps 12% on revenue beat'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Trump does not have presidential immunity in January 6 case, federal appeals court rules'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Trump does not have presidential immunity in January 6 case, federal appeals court rules'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Trump does not have presidential immunity in January 6 case, federal appeals court rules'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Cannabis use linked to anxiety diagnoses, worsened anxiety disorders: Ontario study'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Cannabis use linked to anxiety diagnoses, worsened anxiety disorders: Ontario study'}\n",
    "2024-02-06 18:40:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://ground.news/>\n",
    "{'title': 'Cannabis use linked to anxiety diagnoses, worsened anxiety disorders: Ontario study'}\n",
    "2024-02-06 18:40:35 [scrapy.core.engine] INFO: Closing spider (finished)\n",
    "2024-02-06 18:40:35 [scrapy.extensions.feedexport] INFO: Stored json feed (60 items) in: output06_02_2024.json\n",
    "2024-02-06 18:40:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
    "{'downloader/request_bytes': 452,\n",
    " 'downloader/request_count': 2,\n",
    " 'downloader/request_method_count/GET': 2,\n",
    " 'downloader/response_bytes': 80805,\n",
    " 'downloader/response_count': 2,\n",
    " 'downloader/response_status_count/200': 2,\n",
    " 'elapsed_time_seconds': 7.434112,\n",
    " 'feedexport/success_count/FileFeedStorage': 1,\n",
    " 'finish_reason': 'finished',\n",
    " 'finish_time': datetime.datetime(2024, 2, 6, 17, 40, 35, 715840),\n",
    " 'httpcompression/response_bytes': 942904,\n",
    " 'httpcompression/response_count': 1,\n",
    " 'item_scraped_count': 60,\n",
    " 'log_count/DEBUG': 65,\n",
    " 'log_count/INFO': 11,\n",
    " 'response_received_count': 2,\n",
    " 'robotstxt/request_count': 1,\n",
    " 'robotstxt/response_count': 1,\n",
    " 'robotstxt/response_status_count/200': 1,\n",
    " 'scheduler/dequeued': 1,\n",
    " 'scheduler/dequeued/memory': 1,\n",
    " 'scheduler/enqueued': 1,\n",
    " 'scheduler/enqueued/memory': 1,\n",
    " 'start_time': datetime.datetime(2024, 2, 6, 17, 40, 28, 281728)}\n",
    "2024-02-06 18:40:35 [scrapy.core.engine] INFO: Spider closed (finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bdae131-a93b-4d31-8938-d5d50e8bff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_json('./ground_news_scrapy/output06_02_2024.json').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6671e55f-db3f-4173-9419-99097b59bc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU calls for 90 percent emissions cut by 2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU scraps pesticide proposals in another conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Georgia says it seized Russia-bound cargo of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>King Charles III diagnosed with cancer, Buckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbán boycotts parliament session called to ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cannabis use linked to anxiety diagnoses, wors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spanish farmers blockade roads, joining EU pee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI helps scholars read scroll buried when Vesu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Taylor Swift threatens legal action against st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iranian agents suspected of targeting Jews arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Spanish league to denounce fan who touched pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Facebook and Instagram to label all images on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UN nuclear chief says security is still fragil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Journalists say Ukrainian security service spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Argentina president Javier Milei says plans to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>California could legalize psychedelic therapy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Russian court arrests fiction writer in absent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>China economy overtaking U.S. is increasingly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Turkey mourns tens of thousands dead, surround...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UBS to Restart Buybacks This Year as It Integr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NASA discovers 'super-Earth' 137-light years a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Germany doubles its commitment of troops to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>How climate change contributes to wildfires li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Putin will visit Turkey soon to discuss new Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Scientists propose a Category 6 as hurricanes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Palantir stock jumps 12% on revenue beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Trump does not have presidential immunity in J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title\n",
       "0       EU calls for 90 percent emissions cut by 2040\n",
       "1   EU scraps pesticide proposals in another conce...\n",
       "2   Georgia says it seized Russia-bound cargo of e...\n",
       "3   King Charles III diagnosed with cancer, Buckin...\n",
       "4   Orbán boycotts parliament session called to ra...\n",
       "5   Cannabis use linked to anxiety diagnoses, wors...\n",
       "6   Spanish farmers blockade roads, joining EU pee...\n",
       "7   AI helps scholars read scroll buried when Vesu...\n",
       "8   Taylor Swift threatens legal action against st...\n",
       "9   Iranian agents suspected of targeting Jews arr...\n",
       "10  Spanish league to denounce fan who touched pla...\n",
       "11  Facebook and Instagram to label all images on ...\n",
       "12  UN nuclear chief says security is still fragil...\n",
       "13  Journalists say Ukrainian security service spi...\n",
       "19  Argentina president Javier Milei says plans to...\n",
       "20  California could legalize psychedelic therapy ...\n",
       "29  Russian court arrests fiction writer in absent...\n",
       "34  China economy overtaking U.S. is increasingly ...\n",
       "37  Turkey mourns tens of thousands dead, surround...\n",
       "38  UBS to Restart Buybacks This Year as It Integr...\n",
       "39  NASA discovers 'super-Earth' 137-light years a...\n",
       "44  Germany doubles its commitment of troops to th...\n",
       "50  How climate change contributes to wildfires li...\n",
       "51  Putin will visit Turkey soon to discuss new Bl...\n",
       "52  Scientists propose a Category 6 as hurricanes ...\n",
       "53           Palantir stock jumps 12% on revenue beat\n",
       "54  Trump does not have presidential immunity in J..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c8dc58c-0a10-4d83-bc25-ee086ea884f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "627a05ad-2637-49fe-a29d-5727d382b041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common elements: 26\n",
      "Number of elements unique to df: 7\n",
      "Number of elements unique to df2: 1\n"
     ]
    }
   ],
   "source": [
    "# Find common elements\n",
    "common = pd.merge(df, df2, on='title')\n",
    "number_common = len(common)\n",
    "\n",
    "# Find unique elements\n",
    "merged_df = pd.merge(df, df2, on='title', how='outer', indicator=True)\n",
    "unique_to_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "unique_to_df2 = merged_df[merged_df['_merge'] == 'right_only']\n",
    "number_unique_to_df = len(unique_to_df)\n",
    "number_unique_to_df2 = len(unique_to_df2)\n",
    "\n",
    "print(f'Number of common elements: {number_common}')\n",
    "print(f'Number of elements unique to df: {number_unique_to_df}')\n",
    "print(f'Number of elements unique to df2: {number_unique_to_df2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af31a1-1be0-439f-afce-6b5a2a3df3c6",
   "metadata": {},
   "source": [
    "Hemos obtenido menos resultados en scrapy (df2). Scrapy no tiene una forma nativa de \"clicar botones\" para hacer que aparezcan contenidos, ¿puede haber influido en el diferente resultado? Cabe suponer que en función de cómo funcione la web (p.ej. aparición de contenidos dinámicos), puede funcionar mejor una aproximación u otra, y que a la práctica vale la pena comprobar cuál se ajusta más a nuestras necesidades (y posibilidades).\n",
    "\n",
    "Al parecer para ciertos sitios web, una forma de emular el efecto del click (en el sentido de liberar nuevo contenido) es averiguar qué sucede en la pestaña \"XHR\" de la consola del navegador al clicar en el botón \"More stories\". No obstante, en este caso, esta aproximación no ha sido aplicable (parecía efectuarse por otra vía, no mediante XHR/AJAX).\n",
    "\n",
    "Desconozco, por lo demás, qué factor podría hacer que scrapy encuentre algún registro que no encuentre el webdriver (hay un caso)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e623f-222e-4b88-9734-2df9f599782a",
   "metadata": {},
   "source": [
    "En conclusión, en este caso concreto, Selenium webdriver ha sido más eficaz de forma relativamente sencilla y controlada, mientras que con scrapy, al menos con una aproximación básica y no apoyándonos en herramientas externas adicionales, perdemos cierta información."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
